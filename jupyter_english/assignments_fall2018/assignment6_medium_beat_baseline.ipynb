{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):\n",
    "    \n",
    "    features = ['content', 'published', 'title', 'author']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    feature_files = [open(os.path.join(path_to_data,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "    \n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "\n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            \n",
    "            # You code here\n",
    "            for i in range(len(features)):\n",
    "                content = str(json_data[features[i]]).replace('\\n', ' ').replace('\\r', ' ')\n",
    "                content_no_html_tags = strip_tags(content)\n",
    "                feature_files[i].write(str(content_no_html_tags) + '\\n')\n",
    "                #feature_files[i].write(str(json_data[features[i]]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../data/kaggle_medium' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fac6f16443406ba8d69db62094aa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b0c220ba694e66af853e474efc8ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "def TfIdf(path_to_data, inp_filename):\n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    vectorizer = TfidfVectorizer(max_features=100000, ngram_range=(1,2))\n",
    "    X = vectorizer.fit_transform(content)\n",
    "    print(vectorizer.get_feature_names()[:10])\n",
    "#     print(X.shape)\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 00', '00 am', '00 pm', '000', '000 00', '000 000', '000 and', '000 euros', '000 feet']\n",
      "['00', '000', '000 000', '000 at', '000 blog', '000 day', '000 for', '000 google', '000 in', '000 miles']\n"
     ]
    }
   ],
   "source": [
    "X_train_content_sparse, vect_content = TfIdf(PATH_TO_DATA, 'train_content.txt')\n",
    "X_train_title_sparse, vect_title = TfIdf(PATH_TO_DATA, 'train_title.txt')\n",
    "#print(X_train_title_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 00', '00 am', '00 pm', '000', '000 00', '000 000', '000 and', '000 euros', '000 feet']\n",
      "['00', '000', '000 000', '000 at', '000 blog', '000 day', '000 for', '000 google', '000 in', '000 miles']\n"
     ]
    }
   ],
   "source": [
    "print(vect_content.get_feature_names()[:10])\n",
    "print(vect_title.get_feature_names()[:10])\n",
    "#     print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/train_title_matrix.npz',X_train_title_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('../../data/kaggle_medium/train_content_matrix.npz',X_train_content_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 100000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 100000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfIdf_test(path_to_data, inp_filename, vectorizer):\n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    X = vectorizer.transform(content)\n",
    "    #print(vectorizer.get_feature_names()[:10])\n",
    "#     print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_content_sparse = TfIdf_test(PATH_TO_DATA, 'test_content.txt', vect_content)\n",
    "X_test_title_sparse = TfIdf_test(PATH_TO_DATA, 'test_title.txt', vect_title)\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/test_title_matrix.npz', X_test_title_sparse)\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/test_content_matrix.npz', X_test_content_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_content_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_title_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFeature(path_to_data, inp_filename):\n",
    "    df_published = pd.read_csv(os.path.join(path_to_data, inp_filename),\n",
    "                             sep = \" \", header = None)\n",
    "    df_published.columns = ['tag', 'date']\n",
    "    df_published.date = df_published.date.str.replace(r'}$', '')\n",
    "    df_published['date'] = pd.to_datetime(df_published['date'])\n",
    "    df_published['hour'] = df_published.date.dt.hour\n",
    "    df_published['morning'] = (df_published['hour'] <= 9) & (df_published['hour'] >= 6)\n",
    "    df_published['day'] = (df_published['hour'] <= 18) & (df_published['hour'] > 9)\n",
    "    df_published['night'] = (df_published['hour'] > 18) | (df_published['hour'] < 6)\n",
    "    df_published['isWeekend'] = df_published.date.dt.dayofweek >= 5\n",
    "    df_published = df_published.drop(columns=['tag','date'])\n",
    "    return df_published.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22, False, False, True, False],\n",
       "       [7, True, False, False, False],\n",
       "       [13, False, True, False, True],\n",
       "       ...,\n",
       "       [6, True, False, False, True],\n",
       "       [17, False, True, False, True],\n",
       "       [3, False, False, True, False]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse = timeFeature(PATH_TO_DATA, 'train_published.txt')\n",
    "X_train_time_features_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_time_features_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 5)\n"
     ]
    }
   ],
   "source": [
    "X_test_time_features_sparse = timeFeature(PATH_TO_DATA, 'test_published.txt')\n",
    "print(X_test_time_features_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def authorFeature(path_to_data, inp_filename):\n",
    "#     df_author = pd.read_csv(os.path.join(PATH_TO_DATA, inp_filename), sep=' ', header = None)\n",
    "#     df_author.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "#     df_author.twitter = df_author.twitter.str.replace(r'}$', '')\n",
    "#     one_hot = pd.get_dummies(df_author['twitter'])\n",
    "#     df_author = df_author.join(one_hot)\n",
    "#     df_author = df_author.drop(columns=['tag0', 'tag1','tag2','tag3','tag4','twitter'])\n",
    "#     return df_author.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter__'@0723Sam'</th>\n",
       "      <th>twitter__'@0canom'</th>\n",
       "      <th>twitter__'@0guzKilic'</th>\n",
       "      <th>twitter__'@0ptionworkshop'</th>\n",
       "      <th>twitter__'@0rf'</th>\n",
       "      <th>...</th>\n",
       "      <th>twitter__'@zumpang'</th>\n",
       "      <th>twitter__'@zvellas'</th>\n",
       "      <th>twitter__'@zverk0'</th>\n",
       "      <th>twitter__'@zysman'</th>\n",
       "      <th>twitter__'@zzam_'</th>\n",
       "      <th>twitter__'@zzbennett'</th>\n",
       "      <th>twitter__'@zzdoublezz'</th>\n",
       "      <th>twitter__'@zzilch'</th>\n",
       "      <th>twitter__'@zzste'</th>\n",
       "      <th>twitter__None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@aelcenganda',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@vaibhavkhulbe',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@vaibhavkhulbe',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                  tag3        tag4  \\\n",
       "0  {'name':  None,  'url':         'https://medium.com/@Medium',  'twitter':   \n",
       "1  {'name':  None,  'url':         'https://medium.com/@Medium',  'twitter':   \n",
       "2  {'name':  None,  'url':    'https://medium.com/@aelcenganda',  'twitter':   \n",
       "3  {'name':  None,  'url':  'https://medium.com/@vaibhavkhulbe',  'twitter':   \n",
       "4  {'name':  None,  'url':  'https://medium.com/@vaibhavkhulbe',  'twitter':   \n",
       "\n",
       "   twitter__'@0723Sam'  twitter__'@0canom'  twitter__'@0guzKilic'  \\\n",
       "0                    0                   0                      0   \n",
       "1                    0                   0                      0   \n",
       "2                    0                   0                      0   \n",
       "3                    0                   0                      0   \n",
       "4                    0                   0                      0   \n",
       "\n",
       "   twitter__'@0ptionworkshop'  twitter__'@0rf'      ...        \\\n",
       "0                           0                0      ...         \n",
       "1                           0                0      ...         \n",
       "2                           0                0      ...         \n",
       "3                           0                0      ...         \n",
       "4                           0                0      ...         \n",
       "\n",
       "   twitter__'@zumpang'  twitter__'@zvellas'  twitter__'@zverk0'  \\\n",
       "0                    0                    0                   0   \n",
       "1                    0                    0                   0   \n",
       "2                    0                    0                   0   \n",
       "3                    0                    0                   0   \n",
       "4                    0                    0                   0   \n",
       "\n",
       "   twitter__'@zysman'  twitter__'@zzam_'  twitter__'@zzbennett'  \\\n",
       "0                   0                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   0                  0                      0   \n",
       "3                   0                  0                      0   \n",
       "4                   0                  0                      0   \n",
       "\n",
       "   twitter__'@zzdoublezz'  twitter__'@zzilch'  twitter__'@zzste'  \\\n",
       "0                       0                   0                  0   \n",
       "1                       0                   0                  0   \n",
       "2                       0                   0                  0   \n",
       "3                       0                   0                  0   \n",
       "4                       0                   0                  0   \n",
       "\n",
       "   twitter__None  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 23593 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_author.txt'), sep=' ', header = None)\n",
    "df_author.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "df_author.twitter = df_author.twitter.str.replace(r'}$', '')\n",
    "cat_columns = ['twitter']\n",
    "df_author_processed = pd.get_dummies(df_author, prefix_sep=\"__\", columns=cat_columns)\n",
    "df_author_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_dummies = [col for col in df_author_processed \n",
    "               if \"__\" in col \n",
    "               and col.split(\"__\")[0] in cat_columns]\n",
    "# cat_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_columns = list(df_author_processed.columns[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@hitRECord'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@mariabustillos',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@mariabustillos'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@hitRECord'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@LanceUlanoff',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@LanceUlanoff'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://blog.medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@Medium'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                   tag3        tag4  \\\n",
       "0  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "1  {'name':  None,  'url':  'https://medium.com/@mariabustillos',  'twitter':   \n",
       "2  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "3  {'name':  None,  'url':    'https://medium.com/@LanceUlanoff',  'twitter':   \n",
       "4  {'name':  None,  'url':     'https://blog.medium.com/@Medium',  'twitter':   \n",
       "\n",
       "             twitter  \n",
       "0       '@hitRECord'  \n",
       "1  '@mariabustillos'  \n",
       "2       '@hitRECord'  \n",
       "3    '@LanceUlanoff'  \n",
       "4          '@Medium'  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author_test = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_author.txt'), sep=' ', header = None)\n",
    "df_author_test.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "df_author_test.twitter = df_author_test.twitter.str.replace(r'}$', '')\n",
    "df_author_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter__'@007_drive'</th>\n",
       "      <th>twitter__'@02215507'</th>\n",
       "      <th>twitter__'@08181'</th>\n",
       "      <th>twitter__'@0guzKilic'</th>\n",
       "      <th>twitter__'@0x0ece'</th>\n",
       "      <th>...</th>\n",
       "      <th>twitter__'@zntfdr'</th>\n",
       "      <th>twitter__'@zoeschlag'</th>\n",
       "      <th>twitter__'@zopsesen'</th>\n",
       "      <th>twitter__'@zoyander'</th>\n",
       "      <th>twitter__'@zs'</th>\n",
       "      <th>twitter__'@zslayback'</th>\n",
       "      <th>twitter__'@ztsamudzi'</th>\n",
       "      <th>twitter__'@zuosisi44'</th>\n",
       "      <th>twitter__'@zvona'</th>\n",
       "      <th>twitter__None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@mariabustillos',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@LanceUlanoff',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://blog.medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                   tag3        tag4  \\\n",
       "0  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "1  {'name':  None,  'url':  'https://medium.com/@mariabustillos',  'twitter':   \n",
       "2  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "3  {'name':  None,  'url':    'https://medium.com/@LanceUlanoff',  'twitter':   \n",
       "4  {'name':  None,  'url':     'https://blog.medium.com/@Medium',  'twitter':   \n",
       "\n",
       "   twitter__'@007_drive'  twitter__'@02215507'  twitter__'@08181'  \\\n",
       "0                      0                     0                  0   \n",
       "1                      0                     0                  0   \n",
       "2                      0                     0                  0   \n",
       "3                      0                     0                  0   \n",
       "4                      0                     0                  0   \n",
       "\n",
       "   twitter__'@0guzKilic'  twitter__'@0x0ece'      ...        \\\n",
       "0                      0                   0      ...         \n",
       "1                      0                   0      ...         \n",
       "2                      0                   0      ...         \n",
       "3                      0                   0      ...         \n",
       "4                      0                   0      ...         \n",
       "\n",
       "   twitter__'@zntfdr'  twitter__'@zoeschlag'  twitter__'@zopsesen'  \\\n",
       "0                   0                      0                     0   \n",
       "1                   0                      0                     0   \n",
       "2                   0                      0                     0   \n",
       "3                   0                      0                     0   \n",
       "4                   0                      0                     0   \n",
       "\n",
       "   twitter__'@zoyander'  twitter__'@zs'  twitter__'@zslayback'  \\\n",
       "0                     0               0                      0   \n",
       "1                     0               0                      0   \n",
       "2                     0               0                      0   \n",
       "3                     0               0                      0   \n",
       "4                     0               0                      0   \n",
       "\n",
       "   twitter__'@ztsamudzi'  twitter__'@zuosisi44'  twitter__'@zvona'  \\\n",
       "0                      0                      0                  0   \n",
       "1                      0                      0                  0   \n",
       "2                      0                      0                  0   \n",
       "3                      0                      0                  0   \n",
       "4                      0                      0                  0   \n",
       "\n",
       "   twitter__None  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 12204 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_processed = pd.get_dummies(df_author_test, prefix_sep=\"__\", \n",
    "                                   columns=cat_columns)\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove additional columns\n",
    "for col in df_test_processed.columns:\n",
    "    if (\"__\" in col) and (col.split(\"__\")[0] in cat_columns) and col not in cat_dummies:\n",
    "        #print(\"Removing additional feature {}\".format(col))\n",
    "        df_test_processed.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_dummies:\n",
    "    if col not in df_test_processed.columns:\n",
    "        #print(\"Adding missing feature {}\".format(col))\n",
    "        df_test_processed[col] = 0\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_processed = df_test_processed[processed_columns]\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author_processed = df_author_processed.drop(columns=['tag0', 'tag1', 'tag2', 'tag3', 'tag4'])\n",
    "X_train_author_sparse = df_author_processed.values\n",
    "df_test_processed = df_test_processed.drop(columns=['tag0', 'tag1', 'tag2', 'tag3', 'tag4'])\n",
    "X_test_author_sparse = df_test_processed.values\n",
    "print(X_train_author_sparse.shape)\n",
    "print(X_test_author_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(PATH_TO_DATA, 'X_train_author_sparse.npy'), X_train_author_sparse)\n",
    "np.save(os.path.join(PATH_TO_DATA, 'X_test_author_sparse.npy'), X_test_author_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 62540, expected 62313.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e7de76e5e33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n\u001b[1;32m      2\u001b[0m                          \u001b[0mX_train_author_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                          X_train_time_features_sparse]).tocsr()\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    583\u001b[0m                                                     \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                                                     got=A.shape[0]))\n\u001b[0;32m--> 585\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbcol_lengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 62540, expected 62313."
     ]
    }
   ],
   "source": [
    "X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                         X_train_author_sparse, \n",
    "                         X_train_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                        X_test_author_sparse, \n",
    "                        X_test_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA,\n",
    "                                                    'assignment6_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = ridge_test_pred # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
