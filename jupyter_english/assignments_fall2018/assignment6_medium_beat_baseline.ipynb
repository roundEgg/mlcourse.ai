{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) â€“ Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):\n",
    "    \n",
    "    features = ['content', 'published', 'title', 'author']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    feature_files = [open(os.path.join(path_to_data,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "    \n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "\n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            \n",
    "            # You code here\n",
    "            for i in range(len(features)):\n",
    "                content = str(json_data[features[i]]).replace('\\n', ' ').replace('\\r', ' ')\n",
    "                content_no_html_tags = strip_tags(content)\n",
    "                feature_files[i].write(str(content_no_html_tags) + '\\n')\n",
    "                #feature_files[i].write(str(json_data[features[i]]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../../data/kaggle_medium' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1fac6f16443406ba8d69db62094aa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b0c220ba694e66af853e474efc8ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "def TfIdf(path_to_data, inp_filename):\n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    vectorizer = TfidfVectorizer(max_features=100000, ngram_range=(1,2),stop_words='english')\n",
    "    X = vectorizer.fit_transform(content)\n",
    "    print(vectorizer.get_feature_names()[:10])\n",
    "#     print(X.shape)\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 00', '00 greve', '00 pm', '000', '000 00', '000 000', '000 10', '000 100', '000 50']\n",
      "['00', '000', '000 000', '000 blog', '000 cold', '000 day', '000 google', '000 kickstarter', '000 miles', '000 month']\n"
     ]
    }
   ],
   "source": [
    "X_train_content_sparse, vect_content = TfIdf(PATH_TO_DATA, 'train_content.txt')\n",
    "X_train_title_sparse, vect_title = TfIdf(PATH_TO_DATA, 'train_title.txt')\n",
    "#print(X_train_title_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 00', '00 greve', '00 pm', '000', '000 00', '000 000', '000 10', '000 100', '000 50']\n",
      "['00', '000', '000 000', '000 blog', '000 cold', '000 day', '000 google', '000 kickstarter', '000 miles', '000 month']\n"
     ]
    }
   ],
   "source": [
    "print(vect_content.get_feature_names()[:10])\n",
    "print(vect_title.get_feature_names()[:10])\n",
    "#     print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/train_title_matrix_stopword.npz',X_train_title_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('../../data/kaggle_medium/train_content_matrix_stopword.npz',X_train_content_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 100000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_content_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 100000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_title_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfIdf_test(path_to_data, inp_filename, vectorizer):\n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    \n",
    "    X = vectorizer.transform(content)\n",
    "    #print(vectorizer.get_feature_names()[:10])\n",
    "#     print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_content_sparse = TfIdf_test(PATH_TO_DATA, 'test_content.txt', vect_content)\n",
    "X_test_title_sparse = TfIdf_test(PATH_TO_DATA, 'test_title.txt', vect_title)\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/test_title_matrix_stopword.npz', X_test_title_sparse)\n",
    "scipy.sparse.save_npz('../../data/kaggle_medium/test_content_matrix_stopword.npz', X_test_content_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_content_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 100000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_title_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeFeature(path_to_data, inp_filename):\n",
    "    df_published = pd.read_csv(os.path.join(path_to_data, inp_filename),\n",
    "                             sep = \" \", header = None)\n",
    "    df_published.columns = ['tag', 'date']\n",
    "    df_published.date = df_published.date.str.replace(r'}$', '')\n",
    "    df_published['date'] = pd.to_datetime(df_published['date'])\n",
    "    df_published['year'] = df_published.date.dt.year\n",
    "    df_published['month'] = df_published.date.dt.month\n",
    "    df_published['dow'] = df_published.date.dt.dayofweek\n",
    "    df_published['hour'] = df_published.date.dt.hour\n",
    "    df_published['morning'] = (df_published['hour'] <= 9) & (df_published['hour'] >= 6)\n",
    "    df_published['day'] = (df_published['hour'] <= 18) & (df_published['hour'] > 9)\n",
    "    df_published['night'] = (df_published['hour'] > 18) | (df_published['hour'] < 6)\n",
    "    df_published['isWeekend'] = df_published.date.dt.dayofweek >= 5\n",
    "    df_published = df_published.drop(columns=['tag','date'])\n",
    "    return df_published.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  0,  0,  1,  0],\n",
       "       [ 7,  1,  0,  0,  0],\n",
       "       [13,  0,  1,  0,  1],\n",
       "       ...,\n",
       "       [ 6,  1,  0,  0,  1],\n",
       "       [17,  0,  1,  0,  1],\n",
       "       [ 3,  0,  0,  1,  0]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_time_features_sparse = timeFeature(PATH_TO_DATA, 'train_published.txt')\n",
    "X_train_time_features_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62313, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_time_features_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34645, 5)\n"
     ]
    }
   ],
   "source": [
    "X_test_time_features_sparse = timeFeature(PATH_TO_DATA, 'test_published.txt')\n",
    "print(X_test_time_features_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def authorFeature(path_to_data, inp_filename):\n",
    "#     df_author = pd.read_csv(os.path.join(PATH_TO_DATA, inp_filename), sep=' ', header = None)\n",
    "#     df_author.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "#     df_author.twitter = df_author.twitter.str.replace(r'}$', '')\n",
    "#     one_hot = pd.get_dummies(df_author['twitter'])\n",
    "#     df_author = df_author.join(one_hot)\n",
    "#     df_author = df_author.drop(columns=['tag0', 'tag1','tag2','tag3','tag4','twitter'])\n",
    "#     return df_author.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter__'@0723Sam'</th>\n",
       "      <th>twitter__'@0canom'</th>\n",
       "      <th>twitter__'@0guzKilic'</th>\n",
       "      <th>twitter__'@0ptionworkshop'</th>\n",
       "      <th>twitter__'@0rf'</th>\n",
       "      <th>...</th>\n",
       "      <th>twitter__'@zumpang'</th>\n",
       "      <th>twitter__'@zvellas'</th>\n",
       "      <th>twitter__'@zverk0'</th>\n",
       "      <th>twitter__'@zysman'</th>\n",
       "      <th>twitter__'@zzam_'</th>\n",
       "      <th>twitter__'@zzbennett'</th>\n",
       "      <th>twitter__'@zzdoublezz'</th>\n",
       "      <th>twitter__'@zzilch'</th>\n",
       "      <th>twitter__'@zzste'</th>\n",
       "      <th>twitter__None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@aelcenganda',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@vaibhavkhulbe',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@vaibhavkhulbe',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                  tag3        tag4  \\\n",
       "0  {'name':  None,  'url':         'https://medium.com/@Medium',  'twitter':   \n",
       "1  {'name':  None,  'url':         'https://medium.com/@Medium',  'twitter':   \n",
       "2  {'name':  None,  'url':    'https://medium.com/@aelcenganda',  'twitter':   \n",
       "3  {'name':  None,  'url':  'https://medium.com/@vaibhavkhulbe',  'twitter':   \n",
       "4  {'name':  None,  'url':  'https://medium.com/@vaibhavkhulbe',  'twitter':   \n",
       "\n",
       "   twitter__'@0723Sam'  twitter__'@0canom'  twitter__'@0guzKilic'  \\\n",
       "0                    0                   0                      0   \n",
       "1                    0                   0                      0   \n",
       "2                    0                   0                      0   \n",
       "3                    0                   0                      0   \n",
       "4                    0                   0                      0   \n",
       "\n",
       "   twitter__'@0ptionworkshop'  twitter__'@0rf'      ...        \\\n",
       "0                           0                0      ...         \n",
       "1                           0                0      ...         \n",
       "2                           0                0      ...         \n",
       "3                           0                0      ...         \n",
       "4                           0                0      ...         \n",
       "\n",
       "   twitter__'@zumpang'  twitter__'@zvellas'  twitter__'@zverk0'  \\\n",
       "0                    0                    0                   0   \n",
       "1                    0                    0                   0   \n",
       "2                    0                    0                   0   \n",
       "3                    0                    0                   0   \n",
       "4                    0                    0                   0   \n",
       "\n",
       "   twitter__'@zysman'  twitter__'@zzam_'  twitter__'@zzbennett'  \\\n",
       "0                   0                  0                      0   \n",
       "1                   0                  0                      0   \n",
       "2                   0                  0                      0   \n",
       "3                   0                  0                      0   \n",
       "4                   0                  0                      0   \n",
       "\n",
       "   twitter__'@zzdoublezz'  twitter__'@zzilch'  twitter__'@zzste'  \\\n",
       "0                       0                   0                  0   \n",
       "1                       0                   0                  0   \n",
       "2                       0                   0                  0   \n",
       "3                       0                   0                  0   \n",
       "4                       0                   0                  0   \n",
       "\n",
       "   twitter__None  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 23593 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_author.txt'), sep=' ', header = None)\n",
    "df_author.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "df_author.twitter = df_author.twitter.str.replace(r'}$', '')\n",
    "cat_columns = ['twitter']\n",
    "df_author_processed = pd.get_dummies(df_author, prefix_sep=\"__\", columns=cat_columns)\n",
    "df_author_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_dummies = [col for col in df_author_processed \n",
    "               if \"__\" in col \n",
    "               and col.split(\"__\")[0] in cat_columns]\n",
    "# cat_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_columns = list(df_author_processed.columns[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@hitRECord'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@mariabustillos',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@mariabustillos'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@hitRECord'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@LanceUlanoff',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@LanceUlanoff'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://blog.medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>'@Medium'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                   tag3        tag4  \\\n",
       "0  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "1  {'name':  None,  'url':  'https://medium.com/@mariabustillos',  'twitter':   \n",
       "2  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "3  {'name':  None,  'url':    'https://medium.com/@LanceUlanoff',  'twitter':   \n",
       "4  {'name':  None,  'url':     'https://blog.medium.com/@Medium',  'twitter':   \n",
       "\n",
       "             twitter  \n",
       "0       '@hitRECord'  \n",
       "1  '@mariabustillos'  \n",
       "2       '@hitRECord'  \n",
       "3    '@LanceUlanoff'  \n",
       "4          '@Medium'  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_author_test = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_author.txt'), sep=' ', header = None)\n",
    "df_author_test.columns = ['tag0', 'tag1', 'tag2', 'tag3', 'tag4', 'twitter']\n",
    "df_author_test.twitter = df_author_test.twitter.str.replace(r'}$', '')\n",
    "df_author_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag0</th>\n",
       "      <th>tag1</th>\n",
       "      <th>tag2</th>\n",
       "      <th>tag3</th>\n",
       "      <th>tag4</th>\n",
       "      <th>twitter__'@007_drive'</th>\n",
       "      <th>twitter__'@02215507'</th>\n",
       "      <th>twitter__'@08181'</th>\n",
       "      <th>twitter__'@0guzKilic'</th>\n",
       "      <th>twitter__'@0x0ece'</th>\n",
       "      <th>...</th>\n",
       "      <th>twitter__'@zntfdr'</th>\n",
       "      <th>twitter__'@zoeschlag'</th>\n",
       "      <th>twitter__'@zopsesen'</th>\n",
       "      <th>twitter__'@zoyander'</th>\n",
       "      <th>twitter__'@zs'</th>\n",
       "      <th>twitter__'@zslayback'</th>\n",
       "      <th>twitter__'@ztsamudzi'</th>\n",
       "      <th>twitter__'@zuosisi44'</th>\n",
       "      <th>twitter__'@zvona'</th>\n",
       "      <th>twitter__None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@mariabustillos',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@HITRECORD.org',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://medium.com/@LanceUlanoff',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'name':</td>\n",
       "      <td>None,</td>\n",
       "      <td>'url':</td>\n",
       "      <td>'https://blog.medium.com/@Medium',</td>\n",
       "      <td>'twitter':</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag0   tag1    tag2                                   tag3        tag4  \\\n",
       "0  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "1  {'name':  None,  'url':  'https://medium.com/@mariabustillos',  'twitter':   \n",
       "2  {'name':  None,  'url':   'https://medium.com/@HITRECORD.org',  'twitter':   \n",
       "3  {'name':  None,  'url':    'https://medium.com/@LanceUlanoff',  'twitter':   \n",
       "4  {'name':  None,  'url':     'https://blog.medium.com/@Medium',  'twitter':   \n",
       "\n",
       "   twitter__'@007_drive'  twitter__'@02215507'  twitter__'@08181'  \\\n",
       "0                      0                     0                  0   \n",
       "1                      0                     0                  0   \n",
       "2                      0                     0                  0   \n",
       "3                      0                     0                  0   \n",
       "4                      0                     0                  0   \n",
       "\n",
       "   twitter__'@0guzKilic'  twitter__'@0x0ece'      ...        \\\n",
       "0                      0                   0      ...         \n",
       "1                      0                   0      ...         \n",
       "2                      0                   0      ...         \n",
       "3                      0                   0      ...         \n",
       "4                      0                   0      ...         \n",
       "\n",
       "   twitter__'@zntfdr'  twitter__'@zoeschlag'  twitter__'@zopsesen'  \\\n",
       "0                   0                      0                     0   \n",
       "1                   0                      0                     0   \n",
       "2                   0                      0                     0   \n",
       "3                   0                      0                     0   \n",
       "4                   0                      0                     0   \n",
       "\n",
       "   twitter__'@zoyander'  twitter__'@zs'  twitter__'@zslayback'  \\\n",
       "0                     0               0                      0   \n",
       "1                     0               0                      0   \n",
       "2                     0               0                      0   \n",
       "3                     0               0                      0   \n",
       "4                     0               0                      0   \n",
       "\n",
       "   twitter__'@ztsamudzi'  twitter__'@zuosisi44'  twitter__'@zvona'  \\\n",
       "0                      0                      0                  0   \n",
       "1                      0                      0                  0   \n",
       "2                      0                      0                  0   \n",
       "3                      0                      0                  0   \n",
       "4                      0                      0                  0   \n",
       "\n",
       "   twitter__None  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 12204 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_processed = pd.get_dummies(df_author_test, prefix_sep=\"__\", \n",
    "                                   columns=cat_columns)\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove additional columns\n",
    "for col in df_test_processed.columns:\n",
    "    if (\"__\" in col) and (col.split(\"__\")[0] in cat_columns) and col not in cat_dummies:\n",
    "        #print(\"Removing additional feature {}\".format(col))\n",
    "        df_test_processed.drop(col, axis=1, inplace=True)\n",
    "        \n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_dummies:\n",
    "    if col not in df_test_processed.columns:\n",
    "        #print(\"Adding missing feature {}\".format(col))\n",
    "        df_test_processed[col] = 0\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_processed = df_test_processed[processed_columns]\n",
    "df_test_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_author_processed = df_author_processed.drop(columns=['tag0', 'tag1', 'tag2', 'tag3', 'tag4'])\n",
    "X_train_author_sparse = df_author_processed.values\n",
    "df_test_processed = df_test_processed.drop(columns=['tag0', 'tag1', 'tag2', 'tag3', 'tag4'])\n",
    "X_test_author_sparse = df_test_processed.values\n",
    "print(X_train_author_sparse.shape)\n",
    "print(X_test_author_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(PATH_TO_DATA, 'X_train_author_sparse.npy'), X_train_author_sparse)\n",
    "np.save(os.path.join(PATH_TO_DATA, 'X_test_author_sparse.npy'), X_test_author_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_author_sparse)\n",
    "type(X_train_content_sparse)\n",
    "# type(X_train_time_features_sparse)\n",
    "# type(X_train_title_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_author_sparse = csr_matrix(X_train_author_sparse)\n",
    "X_train_time_features_sparse = csr_matrix(X_train_time_features_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                         X_train_author_sparse, \n",
    "                         X_train_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                        X_test_author_sparse, \n",
    "                        X_test_time_features_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=17, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here\n",
    "ridge = Ridge(random_state=17)\n",
    "ridge.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.086391615411802"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_pred = ridge.predict(X_valid_sparse)\n",
    "valid_mae = mean_absolute_error(y_valid, ridge_pred)\n",
    "valid_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(y_valid, bins=30, alpha=.5, color='red', label='true', range=(0,10));\n",
    "plt.hist(ridge_pred, bins=30, alpha=.5, color='green', label='pred', range=(0,10));\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "ridge.fit(X_train_sparse, y_train)\n",
    "ridge_test_pred = ridge.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred, os.path.join(PATH_TO_DATA,\n",
    "                                                    'assignment6_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(ridge_test_pred), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 4.33328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.988730393775304\n"
     ]
    }
   ],
   "source": [
    "ridge_test_pred_modif = np.median(ridge_test_pred)#(ridge_test_pred + score) / 2# You code here\n",
    "print(ridge_test_pred_modif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
